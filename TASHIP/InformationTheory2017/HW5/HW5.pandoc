---
title: Homework 5
author: Dilawar Singh
institute: NCBS Bangalore
email: dilawars@ncbs.res.in
geometry: right=5cm, marginparwidth=4cm
date : \today 
fontfamily: libertine
header-includes:
    - \usepackage{pgfplots}
    - \usetikzlibrary{calc,positioning}
    - \usepackage{libertine,mathpazo}
---

# Problem 1: Transmitting information across a channel (8 points)

Consider the discrete memoryless channel $Y=X+Z (\text{mod}\; 11)$, where $Z$
is uniformly distributed on the alphabet $\{1,2,3\}$.

$$ Z = \begin{bmatrix} 1 & 2 & 3 \\ 1/3 & 1/3 & 1/3  \end{bmatrix}$$

and $X \in \{0,1,\ldots,10\}$. Assume that Z independent of X.

a. Find the capacity.
b. What is the maximizing $p^*(x)$.

## Solution 

The capacity of the channel is $I(X;Y)$ (by definition). The transitions are
shown in @fig:p51 .

![Transition diagram.](./network.png){#fig:p51 width=100%}

To compute the channel capacity we need to find $p(x)$ which maximizes $I(Y;X) =
H(Y) - H(Y|X)$. 

$H(Y|X=0) = H(1/3,1/3,1/3) = 1.584963$ bits. And, $H(Y|X=0)=H(Y|X=1)= \ldots =
H(Y|X=10)$.

$$ H(Y|X) = \Pr(X=0) H(Y|X=0) + \Pr(X=1)H(Y|X=1) + \ldots \Pr(X=10)H(Y|X=10) $$
$$ H(Y|X) = 1.584963 \left(\Pr(X=0)+\Pr(X=1)+\ldots \Pr(X=10) \right)$$

And, 
$$\Pr(Y=1) = \frac{1}{3} \left( \Pr(X=9) + \Pr(X=10) + \Pr(X=0) \right)$$
$$\Pr(Y=2) = \frac{1}{3} \left( \Pr(X=9) + \Pr(X=10) + \Pr(X=8) \right)$$
\vdots
$$\Pr(Y=10) = \frac{1}{3} \left( \Pr(X=9) + \Pr(X=8) + \Pr(X=7) \right)$$

Given that we need to maximize $H(Y) - H(Y|X)$ for some values of $\Pr(X)$. For
instance, for equiprobable $X$, we have

$H(Y|X) = 1.5849$ bits and $H(Y)=3.459$ bits. Therefox $I(X,Y) = 1.8745$ bits.
__Is there any other distribution of $X$ for which $I(X;Y)$ is larger that this
value?__


# Problem 2: [C&T 8.9] (7 Points)

The Z channel has binary input and output alphabets and transition probabilities
$p(y|x)$ given by the following matrix:

$$ Q = \begin{bmatrix} 1 & 0 \\ 1/2  & 1/2 \end{bmatrix}$$ where $ x,y\in {0,
1}$.

[Why is it called the Z-channel?]

\begin{tikzpicture}[scale=1, every node/.style={} ]
    \node (l0) {0};
    \node[below=of l0] (l1) {1};
    \node (r0) [right=of l0] {0};
    \node (r1) [right=of l1] {1};
    \draw[->,thick] (l0) edge[above] node{1} (r0);
    \draw[->,thick] (l1) edge[above] node{1/2} (r0);
    \draw[->,thick] (l1) edge[above] node{1/2} (r1);
\end{tikzpicture}    

Find the capacity of the Z channel and the maximizing input probability distribution.

## Solution

Lets assume $\Pr(X=0) = p_0$. Then $\Pr(X=1) = 1-p_0$. Similar to previous
problem, we compute $I(X;Y) = H(Y) - H(Y|X)$

\begin{align}
H(Y)  &= H\left( 
        p_0 \Pr(Y=0|X=0) 0
        , (1-p_0) \Pr(Y=0|X=1) \frac{1}{2}
        , p_0 \Pr(Y=1|X=0) 0 
        , (1-p_0) \Pr(Y=1|X=1) \frac{1}{2} \right) \\
      &= H\left( p_0, \frac{1-p_0}{2}, 0, \frac{1-p_0}{2} \right) \\
H(Y|X) &= p_0 H(1,0) + (1-p_0) H(1/2, 1/2) = 1-p_0
\end{align}

Therefore $I(X;Y) = H\left( p_0, \frac{1-p_0}{2}, 0, \frac{1-p_0}{2} \right) -
(1-p_0) = - p_0 \log(p_0) - (1-p_0)\log(\frac{1-p_0}{2})-1+p_0$.

My calculation shows the this function is maximum at $p_0 = \frac{2}{3}$.

\begin{tikzpicture}[scale=1]
    \begin{axis}[ xlabel=p,ylabel={I(X;Y)}, ]
    \addplot [color=blue, domain=0:1] gnuplot [ raw gnuplot ] {
        f(x) = -x * log(x) / log(2) - (1-x) * log( 1-x) / log(2) + 1 - 1 + x;
        plot [x=0:0.99] f(x);
    };
    \end{axis}
\end{tikzpicture}

# Problem 3. [Optional][C&T 8.10] (8 Points) 

For the Z channel of the previous problem, assume that we choose a $(2^{nR},n)$
code at random, where each codeword is a sequence of _fair_ coin tosses. This
will not achieve capacity. Find the maximum rate R such that the probability of
error $P_e^n$, averaged over randomly generated codes, tends to zero as the
block length $n$ to infinity.

## Solution

The solution to this problem is Threom 7.7.1 (pp 200, Second edition) of
text-book. Here I show a simulation.

Let a message $x \in X$ was sent which is recived as $x'$ due to errors. We decode
$x'$ as following:

For each $y\in X$ we compute the Hamming distance between $x'$ and $y$. We select
the code with lowest Hamming distance as $x$. If there are more than one code
with lowest Hamming distance, we declare it to be an error.

Since we are simulating, we compare the deocded $x'$ with actual code which was
sent. If they don't match, we declare it to be error. Note that this is not
neccessary.

In following figure we see that as $n$ increases, the error rate goes to 0. For
each case 200 codes were sent. 

![Solution](./hw53.py.png)

The script can be found
[here](http://github.com/dilawar/courses/raw/master/TASHIP/InformationTheory2017/HW5/hw53.py).
